tip OpenAI 에 매개변수 model 을 전달했다. model 은 사용할 기본 모델을 지정하는 매개변수로, LLM 이나 채팅 모델 사용 시 필요한 가장 일반적인 매개변수다. 대부분의 제공업체는 성능과 비용 간 트레이드오프 "de애를 고려해 여러 모델을 제공한다 /uniFF08LLM 은 성능이 뛰어나지만 비용이 높고 응답 속도가 느리다）. 오픈 AI 가 제 공하는 모델 목록 /uniFF08https /uniFF1A//oreil. ly/dM886/uniFF09 을 확인하자. 대부분의 LLM 은 다음 매개변수를 지원한다.

-  temperat 니 re ： 출력 생성에 사용하는 샘플링 알고리즘을 제어한다. 낮은 값（예: 0.1） 은 보다 예측 가 능한 결과를 만든다. 반면, 높은 값（예 : 0.9/uniFF09 은 창의적이거나 예상치 못한 결과를 만들어낸다. 이 매개 변수는 작업에 따라 서로 다른 값이 필요하다. 예를 들어, 구조화된 출력물을 생성할 때는 낮은 값을 사 용하는 편이 좋다. 반면, 창의적인 글쓰기 같은 작업은 높은 값을 사용해야 더 나은 결과를 얻는다.
-  max\_tokens: 출력 크기와 비용을 제한한다. 낮은 값을 설정하면 LLM 이 자연스러운 마무리에 도달하 기 전에 출력을 중단한다.

이 외에도 모델마다 서로 다른 매개변수를 지원한다. 선택한 모델의 문서를 참고하길 권한다. 오픈시는 매개 변수를 정리한 문서 /uniFF08https/uniFF1A//oreil. ly/5O7M/uniFF09 를 제공한다.

기본 LLM 과 달리 채팅 모델 인터페이스는 사용자와 모델이 양방향 대화를 주고받는다. 별 도의 인터페이스를 제공하는 이유는 오픈 AI 같이 사용자가 많은 LLM 제공업체가 메시지를 user （사용자）, assistant （어시스턴트）, system （시스템） 같은 역할로 구분하기 때문이다. 이때 role （역할）은 메시지의 콘텐츠 유형을 나타낸다.

-  system: 사용자 질문에 답변하는 데 사용하는 지시 사항
-  user: 사용자의 쿼리와 사용자가 생성한 그 밖의 모든 콘텐츠
-  assistant /uniFF1A 채팅 모델이 생성한콘텐츠

채팅 모델 인터페이스로 AI 챗봇 애플리케이션에서 구성을 쉽게 변환하고 관리할 수 있다. 다음은 랭체인의 ChatOpenAI 모델을 활용한 구현이다.2

## 코드 1-2 채팅모델 호출

from langchain\_openai,chat\_models import ChatOpenAI

Python

2 랭체인은 80 개 이상의 채팅 모델 패키지를 제공한다 （2025 년 4 월）, 지원하는 채팅 모델 목록은 h 仕 P：// 伍亡 1y/43 此기止에서 확인할 수 있다.

```
system_msg = SystemMessage/uniFF08 당신은 문장 끝에 느낌표를 세 개 붙여 대답하는 친절한 어시스턴트입니다. ） human_msg = HumanMessage （■프랑스의 수도는 어디인가요?'） model.invoke/uniFF08/uniFF3Bsystemjnsg, human_msg/uniFF3D/uniFF09
```

```
import { ChatOpenAI } from '@langchain/openai'; import { H 니 manMessage, SystemMessage } from '@langchain/core/messages'; const model = new ChatOpenAIO; const prompt = [ new SystemMessage/uniFF08 '당신은 문장 끝에 느낌표를 세 개 붙여 대답하는 친절한 어시스턴트입니다., ）, new H 니 manMessage （'프랑스의 수도는 어디인가요?,）, ]/uniFF1B const response = await model.invoke/uniFF08prompt/uniFF09; JavaScript
```

## 출력

AIMessage （'파리입니다!!!,）

채팅 모델은 사용자 질문에는 포함하지 않았던 SystemMessage 내의 지시를 따른다. 사용자 의 입력을 바탕으로 AI 애플리케이션이 비교적 예측 가능한 방식으로 응답하도록 미리 설정 할수있다.

## 1.3 LLM 프롬프트 템플릿

앞서 프롬프트의 지시 사항이 출력에 미치는 영향을 확인했다. 프롬프트는 LLM 이 컨텍스트 를 이해하고, 질의에 적절한 답변을 생성하도록 유도한다. LLM 제공업체를 물어보는 프롬프 트를 자세히 살펴보자.

<!-- image -->

})

import { PromptTemplate } from '@langchain/core/prompts'; const template = PromptTemplate.fromTemplate ('아래 작성한 컨텍스트 (Context) 를 기반으로 질문 (Question) 에 대답하세요. 제공된 정보로 대답할 수 없는 질문이라면 "모르겠어요." 라고 답하세요. Context: {context} Question: {question} Answer: '); const response = await template.invoke({ context: '거대 언어 모델 (LLM) 은 자연어 처리 (NLP) 분야의 최신 발전을 이끌고 있습니다. 거대 언어 모델은 더 작은 모델보다 우수한 성능을 보이며, NLP 기능을 갖춘 애플리케이션을 개발하는 개발자들에게 매우 중요한 도구가 되었습니다. 개발자들은 Hugging Face 의 'transformers' 라이브러리를 활용하거나, 'openai' 및 'cohere' 라이브러리를 통해 OpenAI 와 Cohere 의 서 비스를 이용하여 거대 언어 모델을 활용할 수 있습니다.,, question: '거대 언어 모델은 어디서 제공하나요?,, })/uniFF1B

## 출력

StringPromptVal 니 e(text= '아래 작성한 컨텍스트 (Context) 를 기반으로 질문 (Question) 에 대답하세요. 제공된 정보로 대답할 수 없는 질문이라면 "모르겠어요." 라고 답하세요.

라이브러 의 서비스

Context: 거대 언어 모델 (LLM) 은 자연어 처리 (NLP) 분야의 최신 발전을 이끌고 있습니다. 거대 언어 모델은 더 작은 모델보다 우수한 성능을 보이며, NLP 기능을 갖춘 애플리케이션을 개발하는 개발자들에게 매우 중요한 도구가 되었습니다. 개발자들은 Hugging Face 의 ,transformers' 리를 활용하거나, 'openai' 및 'cohere' 라이브러리를 통해 OpenAI 와 Cohere 를 이용하여 거대 언어 모델을 활용할 수 있습니다.

'question':

'거대 언어 모델은 어디서 제공하나요?,

JavaScript