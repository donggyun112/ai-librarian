"""
Test script for the new LLM-based autonomous routing system.

This script demonstrates the difference between:
1. Old rule-based routing (executes multiple tools)
2. New LLM-based autonomous routing (selects ONE tool intelligently)
"""

import os
import sys
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Test questions covering different scenarios
TEST_QUESTIONS = [
    {
        "question": "LangChainì´ ë¬´ì—‡ì¸ê°€ìš”?",
        "expected_tool": "vector_db",
        "reason": "ì •ì˜/ì„¤ëª… ì§ˆë¬¸ â†’ ë¬¸ì„œ ê²€ìƒ‰ì´ ì í•©"
    },
    {
        "question": "2024ë…„ ìµœì‹  AI íŠ¸ë Œë“œëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
        "expected_tool": "web_search",
        "reason": "ìµœì‹  ì •ë³´ â†’ ì›¹ ê²€ìƒ‰ì´ í•„ìˆ˜"
    },
    {
        "question": "AIê°€ ì¸ê°„ì˜ ì‚¶ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
        "expected_tool": "llm_direct",
        "reason": "ì¼ë°˜ì /ì² í•™ì  ì§ˆë¬¸ â†’ LLM ì§ì ‘ ë‹µë³€ì´ ì í•©"
    },
    {
        "question": "RAGì™€ íŒŒì¸íŠœë‹ì˜ ì°¨ì´ì ì„ ë¹„êµí•˜ê³ , ìµœì‹  ì—°êµ¬ ë™í–¥ë„ ì•Œë ¤ì£¼ì„¸ìš”",
        "expected_tool": "hybrid",
        "reason": "ë³µí•© ì§ˆë¬¸ (ì •ì˜ + ìµœì‹  ì •ë³´) â†’ í•˜ì´ë¸Œë¦¬ë“œ í•„ìš”"
    }
]


def test_llm_router_only():
    """Test LLM router without executing tools (just routing decisions)."""
    print("=" * 80)
    print("ğŸ§ª TEST 1: LLM Router Decision Testing (No Tool Execution)")
    print("=" * 80)
    print()

    from src.langchain.agents.llm_router import LLMRouter

    # Initialize router
    openai_api_key = os.getenv("OPENAI_API_KEY")
    if not openai_api_key:
        print("âŒ Error: OPENAI_API_KEY not found in environment")
        return

    router = LLMRouter(openai_api_key=openai_api_key)

    # Test each question
    for i, test_case in enumerate(TEST_QUESTIONS, 1):
        print(f"\n{'â”€' * 80}")
        print(f"ğŸ“ Test Case {i}/{len(TEST_QUESTIONS)}")
        print(f"{'â”€' * 80}")
        print(f"Question: {test_case['question']}")
        print(f"Expected Tool: {test_case['expected_tool']}")
        print(f"Reason: {test_case['reason']}")
        print()

        # Get routing decision
        decision = router.route(test_case['question'])

        # Display result
        print(f"âœ… LLM Router Decision:")
        print(f"   - Selected Tool: {decision.primary_tool.value}")
        print(f"   - Confidence: {decision.confidence:.2f}")
        print(f"   - Reasoning: {decision.reasoning}")

        if decision.fallback_tool:
            print(f"   - Fallback Tool: {decision.fallback_tool.value}")

        if decision.requires_multiple_tools:
            print(f"   - Requires Multiple Tools: Yes")
            print(f"   - Additional Tools: {[t.value for t in decision.additional_tools]}")

        # Check if correct
        is_correct = decision.primary_tool.value == test_case['expected_tool']
        result_emoji = "âœ…" if is_correct else "âš ï¸"
        print(f"\n{result_emoji} Result: {'CORRECT' if is_correct else 'DIFFERENT (but may still be valid)'}")

    # Show statistics
    print(f"\n{'=' * 80}")
    print("ğŸ“Š Router Statistics:")
    print(f"{'=' * 80}")
    stats = router.get_stats()
    print(f"Total Routings: {stats['total_routings']}")
    print(f"Average Confidence: {stats['average_confidence']:.2f}")
    print(f"Tool Selections:")
    for tool, count in stats['tool_selections'].items():
        print(f"  - {tool}: {count}")


def test_autonomous_vs_rule_based():
    """Compare autonomous routing vs rule-based routing."""
    print("\n\n")
    print("=" * 80)
    print("ğŸ§ª TEST 2: Autonomous vs Rule-Based Routing Comparison")
    print("=" * 80)
    print()

    # Note: This test requires Milvus to be running
    # We'll just show the conceptual difference here

    print("âš ï¸  Full integration test requires:")
    print("   1. Milvus/Zilliz cluster running")
    print("   2. Vector store initialized")
    print("   3. Documents indexed")
    print()
    print("ğŸ“‹ Conceptual Comparison:")
    print()
    print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
    print("â”‚ Aspect                  â”‚ Rule-Based           â”‚ Autonomous LLM       â”‚")
    print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
    print("â”‚ Decision Making         â”‚ Hard-coded rules     â”‚ LLM reasoning        â”‚")
    print("â”‚ Tools Executed          â”‚ Multiple (wasteful)  â”‚ Single (efficient)   â”‚")
    print("â”‚ Adaptability            â”‚ Static               â”‚ Dynamic              â”‚")
    print("â”‚ Reasoning Transparency  â”‚ None                 â”‚ Full explanation     â”‚")
    print("â”‚ Cost                    â”‚ Higher (å¤š API calls)â”‚ Lower (1-2 calls)    â”‚")
    print("â”‚ Latency                 â”‚ Slower (å¤š tools)    â”‚ Faster (1 tool)      â”‚")
    print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
    print()

    # Example of what happens in each mode
    print("ğŸ“Œ Example: '2024ë…„ ìµœì‹  AI íŠ¸ë Œë“œëŠ”?'")
    print()
    print("âŒ OLD Rule-Based Mode:")
    print("   1. Calculate confidence: vector_db=0.2, web=0.9, llm=0.3")
    print("   2. All above threshold â†’ Execute ALL THREE")
    print("   3. Execute vector_db â†’ No results")
    print("   4. Execute web_search â†’ Good results âœ“")
    print("   5. Execute llm_direct â†’ Generic answer")
    print("   6. Select best result")
    print("   Result: 3 API calls, wasted time/money")
    print()
    print("âœ… NEW Autonomous Mode:")
    print("   1. LLM analyzes: 'ìµœì‹ ' â†’ needs current info")
    print("   2. LLM decides: Use web_search ONLY")
    print("   3. Execute web_search â†’ Good results âœ“")
    print("   4. Done")
    print("   Result: 2 API calls (1 routing + 1 tool), efficient!")
    print()


def show_usage_guide():
    """Show how to use the new system."""
    print("\n\n")
    print("=" * 80)
    print("ğŸ“– USAGE GUIDE: How to Use Autonomous Routing")
    print("=" * 80)
    print()

    print("1ï¸âƒ£  Enable Autonomous Routing (Default):")
    print()
    print("```python")
    print("from src.langchain.services.langchain_answer_service import LangChainAnswerService")
    print()
    print("service = LangChainAnswerService(")
    print("    vector_store=vector_store,")
    print("    embedding_service=embedding_service,")
    print("    use_autonomous_routing=True,  # â† NEW! Default is True")
    print("    enable_reflection=False       # â† Optional: retry on failure")
    print(")")
    print()
    print("answer = service.get_answer(question)")
    print("```")
    print()

    print("2ï¸âƒ£  Check Routing Decision:")
    print()
    print("```python")
    print("# Routing info is in answer metadata")
    print("print(answer.metadata['routing_mode'])        # 'autonomous_llm'")
    print("print(answer.metadata['selected_tool'])       # 'vector_db' | 'web_search' | 'llm_direct'")
    print("print(answer.metadata['routing_confidence'])  # 0.0 - 1.0")
    print("print(answer.metadata['routing_reasoning'])   # LLM's explanation")
    print("```")
    print()

    print("3ï¸âƒ£  Enable Reflection (Advanced):")
    print()
    print("```python")
    print("service = LangChainAnswerService(")
    print("    vector_store=vector_store,")
    print("    embedding_service=embedding_service,")
    print("    use_autonomous_routing=True,")
    print("    enable_reflection=True  # â† Automatically retry with different tool if first fails")
    print(")")
    print("```")
    print()

    print("4ï¸âƒ£  Fallback to Rule-Based (If Needed):")
    print()
    print("```python")
    print("service = LangChainAnswerService(")
    print("    vector_store=vector_store,")
    print("    embedding_service=embedding_service,")
    print("    use_autonomous_routing=False  # â† Use old rule-based routing")
    print(")")
    print("```")
    print()


def main():
    """Run all tests."""
    print("\n")
    print("â•”" + "â•" * 78 + "â•—")
    print("â•‘" + " " * 15 + "LLM-based Autonomous Routing Test Suite" + " " * 23 + "â•‘")
    print("â•š" + "â•" * 78 + "â•")
    print()

    # Test 1: Router decisions only
    try:
        test_llm_router_only()
    except Exception as e:
        print(f"\nâŒ Test 1 failed: {str(e)}")
        import traceback
        traceback.print_exc()

    # Test 2: Comparison
    test_autonomous_vs_rule_based()

    # Usage guide
    show_usage_guide()

    print("\n" + "=" * 80)
    print("âœ… All tests completed!")
    print("=" * 80)
    print()
    print("ğŸ’¡ Next Steps:")
    print("   1. Start your Milvus/Zilliz cluster")
    print("   2. Update streamlit_app.py to use autonomous routing")
    print("   3. Run: uv run streamlit run streamlit_app.py")
    print("   4. Ask questions and check the routing decisions!")
    print()


if __name__ == "__main__":
    main()
